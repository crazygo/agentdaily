[
  {
    "title": "Andrej Karpathy introduces \"Claws\" - A new layer in the AI stack",
    "description": "Andrej Karpathy tweeted about buying a Mac Mini to experiment with 'Claws' - a new layer on top of LLM agents. Claws handle orchestration, scheduling, context, tool calls, and persistence. Karpathy notes that while he's cautious about running OpenClaw specifically, he loves the concept and sees it as the next evolution of the AI stack. Multiple implementations are emerging: NanoClaw (~4000 lines of code), nanobot, zeroclaw, ironclaw, and picoclaw.",
    "author": "Andrej Karpathy (via Simon Willison)",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Feb/21/andrej-karpathy-claws/",
    "published_date": "2026-02-21",
    "topics": ["ai-agents", "openclaw", "claws", "orchestration", "llm-agents", "ai-stack"],
    "type": "opinion"
  },
  {
    "title": "OpenAI achieves 1,200+ tokens/second with GPT-5.3-Codex-Spark",
    "description": "Thibault Sottiaux from OpenAI announced that GPT-5.3-Codex-Spark is now serving at over 1,200 tokens per second after a 30% speed improvement. This represents a significant milestone in LLM inference speed for coding models.",
    "author": "Thibault Sottiaux (OpenAI)",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Feb/21/gpt-53-codex-speed/",
    "published_date": "2026-02-21",
    "topics": ["openai", "gpt-53", "codex", "llm-performance", "inference-speed", "ai-coding"],
    "type": "technical"
  },
  {
    "title": "Simon Willison adds \"beats\" feature to blog - TILs, releases, museums, tools, research",
    "description": "Simon Willison introduced a new feature called 'beats' to his blog, adding five types of content corresponding to activity elsewhere: TILs (Today I Learned), releases, museums, tools, and research. This provides a more comprehensive view of his work across different platforms and activities.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Feb/20/beats/",
    "published_date": "2026-02-20",
    "topics": ["blogging", "tools", "workflow", "content-management"],
    "type": "opinion"
  },
  {
    "title": "Taalas serves Llama 3.1 8B at 17,000 tokens/second",
    "description": "Canadian hardware startup Taalas announced their first product - a custom hardware implementation of Llama 3.1 8B running at 17,000 tokens/second. Their 'Silicon Llama' uses aggressive quantization (3-bit and 6-bit parameters). The demo is available at chatjimmy.ai and is so fast it looks like a screenshot.",
    "author": "Taalas",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Feb/20/taalas/",
    "published_date": "2026-02-20",
    "topics": ["hardware", "llama", "llm-performance", "quantization", "inference", "local-llms"],
    "type": "technical"
  },
  {
    "title": "ggml.ai joins Hugging Face to ensure long-term progress of Local AI",
    "description": "Georgi Gerganov's ggml.ai (creator of llama.cpp) is joining Hugging Face. This is significant because Georgi's work on llama.cpp in March 2023 made it possible to run local LLMs on consumer hardware, kicking off the local model movement. The partnership aims for seamless integration with Transformers and better user experience for ggml-based software.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Feb/20/ggml-hugging-face/",
    "published_date": "2026-02-20",
    "topics": ["open-source", "hugging-face", "llama-cpp", "local-llms", "ggml", "acquisition"],
    "type": "opinion"
  },
  {
    "title": "Prompt caching enables long-running agentic products like Claude Code",
    "description": "Thariq Shihipar from Anthropic explained that prompt caching makes products like Claude Code feasible by reusing computation from previous roundtrips, significantly decreasing latency and cost. High cache hit rates decrease costs and enable more generous rate limits. Anthropic monitors cache hit rates with alerts and declares SEVs if they drop too low.",
    "author": "Thariq Shihipar (Anthropic)",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Feb/20/prompt-caching/",
    "published_date": "2026-02-20",
    "topics": ["prompt-caching", "anthropic", "claude-code", "ai-agents", "optimization", "cost"],
    "type": "technical"
  },
  {
    "title": "SWE-bench February 2026 leaderboard: Claude 4.5 Opus leads at 76.8%",
    "description": "The SWE-bench Verified benchmark was updated with results for current models. Claude 4.5 Opus (high reasoning) leads at 76.8%, followed by Gemini 3 Flash (75.8%) and MiniMax M2.5 (75.8%). Notable: Claude 4.5 Opus beats 4.6 Opus by ~1 percentage point. Chinese models perform strongly: MiniMax M2.5, GLM-5, Kimi K2.5, and DeepSeek V3.2 all make top 10. GPT-5.2 ranks 6th; GPT-5.3-Codex is not represented.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Feb/19/swe-bench/",
    "published_date": "2026-02-19",
    "topics": ["benchmarks", "swe-bench", "coding-agents", "ai-in-china", "claude", "gemini", "minimax"],
    "type": "technical"
  },
  {
    "title": "Simon Willison's experience with 'parallel agent psychosis'",
    "description": "Simon Willison shared a humorous but insightful experience about the downsides of parallel AI coding agents: he lost a whole feature he'd written yesterday, couldn't find the branch/worktree/instance with it. Eventually discovered he'd been hacking on a prototype in /tmp that was lost when his computer crashed, but Claude Code was able to extract the code from ~/.claude/projects/ session logs and recreate the missing feature.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Feb/19/parallel-agent-psychosis/",
    "published_date": "2026-02-19",
    "topics": ["parallel-agents", "claude-code", "ai-coding", "workflow", "session-management"],
    "type": "discussion"
  },
  {
    "title": "Google releases Gemini 3.1 Pro with improved SVG performance",
    "description": "Google released Gemini 3.1 Pro, priced at $2/million input and $12/million output tokens - less than half the price of Claude Opus 4.6 with similar benchmark scores. The model boasts improved SVG animation performance. Simon tested it with his standard 'pelican riding a bicycle' prompt, noting the model includes detailed SVG comments and produces creative results (though currently experiencing high demand and slow response times on launch day).",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Feb/19/gemini-31-pro/",
    "published_date": "2026-02-19",
    "topics": ["google", "gemini", "llm-release", "svg", "llm-pricing", "image-generation"],
    "type": "technical"
  },
  {
    "title": "Vibe Coding emerges as dominant AI programming paradigm in February 2026",
    "description": "Vibe Coding has become the hottest trend in AI programming - a paradigm where developers use natural language to describe requirements and completely trust AI-generated code without manual review. GitHub data shows 40%+ efficiency improvement and 34% higher code merge rates. The shift from 'coding' to 'system design' represents a fundamental change in how software is built.",
    "author": "Multiple sources",
    "source": "TechMedia",
    "url": "https://view.inews.qq.com/k/20260220A01UK900",
    "published_date": "2026-02-20",
    "topics": ["vibe-coding", "ai-coding", "paradigm-shift", "productivity", "github-copilot", "cursor"],
    "type": "opinion"
  },
  {
    "title": "25+ years into programming, Simon Willison embraces type hints",
    "description": "After resisting type hints and strong typing for most of his 25-year career because they slowed iteration in REPL environments, Simon Willison is now embracing them. The shift is driven by AI coding agents: if a coding agent is doing all the typing, the benefits of explicitly defining types become much more attractive without the traditional friction cost.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Feb/18/type-hints/",
    "published_date": "2026-02-18",
    "topics": ["programming", "static-typing", "type-hints", "ai-assisted-programming", "programming-languages"],
    "type": "opinion"
  },
  {
    "title": "Paul Ford: 'The A.I. Disruption We've Been Waiting for Has Arrived'",
    "description": "Paul Ford's NYT opinion piece captures the November 2025 moment when AI coding tools suddenly got much better. He describes Claude Code's ability to revive decade-old side projects, completing in hours what would have cost $25,000-$350,000 in 2021. Notable quote: 'All of the people I love hate this stuff, and all the people I hate love it' - capturing the community tension around AI coding.",
    "author": "Paul Ford",
    "source": "TechMedia",
    "url": "https://www.nytimes.com/2026/02/18/opinion/ai-coding-disruption.html",
    "published_date": "2026-02-18",
    "topics": ["ai", "claude-code", "careers", "coding-agents", "ai-ethics", "new-york-times"],
    "type": "opinion"
  },
  {
    "title": "Martin Fowler: LLMs are eating specialty skills, will this elevate Expert Generalists?",
    "description": "Martin Fowler shared insights from Thoughtworks' Future of Software Development Retreat. He noted that LLMs are eating specialty skills, leading to less use of specialist front-end and back-end developers as LLM-driving skills become more important than platform usage details. The key question: will this lead to greater recognition of Expert Generalists, or will LLMs just code around silos rather than eliminating them?",
    "author": "Martin Fowler",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Feb/18/martin-fowler-llm-specialists/",
    "published_date": "2026-02-18",
    "topics": ["careers", "ai", "llms", "ai-assisted-programming", "expert-generalists", "software-development"],
    "type": "opinion"
  },
  {
    "title": "2026 AI coding tools landscape: Cursor, Copilot Workspace, JetBrains AI, ByteDance Trae lead",
    "description": "Comprehensive analysis of AI coding tools in February 2026. Top IDE-based tools: Cursor (v0.45.0, AI-native), GitHub Copilot Workspace (1M token context), JetBrains AI Assistant (Claude 3.7 integration), ByteDance Trae (20M+ users in China). Key trends: evolution from single-point to comprehensive workstations, shift from passive to active AI partnership, and movement from cloud-dependent to hybrid intelligence deployments.",
    "author": "JetBrains Blog",
    "source": "Blog",
    "url": "https://blog.jetbrains.com/ai/2026/02/the-most-popular-ai-tools-what-developers-use-and-why/",
    "published_date": "2026-02-18",
    "topics": ["ai-coding", "cursor", "github-copilot", "jetbrains", "ide", "developer-tools", "claude"],
    "type": "technical"
  },
  {
    "title": "Anthropic releases Claude Sonnet 4.6 with Opus 4.5-level performance",
    "description": "Anthropic released Claude Sonnet 4.6, claiming performance similar to November's Opus 4.5 while maintaining Sonnet pricing ($3/million input, $15/million output vs Opus's $5/$25). Sonnet 4.6 has a knowledge cutoff of August 2025 (vs Opus 4.6's May 2025). Simon tested with the 'pelican riding a bicycle' prompt and found Sonnet 4.6 consistently adds top hats to pelicans.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Feb/17/claude-sonnet-46/",
    "published_date": "2026-02-17",
    "topics": ["anthropic", "claude", "llm-release", "llm-pricing", "svg", "pelican-riding-a-bicycle"],
    "type": "technical"
  },
  {
    "title": "Simon Willison's Rodney CLI v0.4.0 released with community contributions",
    "description": "Simon released Rodney v0.4.0, his CLI tool for browser automation, featuring numerous community contributions: new exit codes, 'rodney assert' command for JavaScript tests, directory-scoped sessions, reload commands, Windows support, and more. The assert command enables testing web apps through shell scripts with checks for element existence, visibility, JS expressions, and accessibility.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Feb/17/rodney-v040/",
    "published_date": "2026-02-17",
    "topics": ["browsers", "testing", "rodney", "projects", "annotated-release-notes", "open-source"],
    "type": "technical"
  },
  {
    "title": "Dimitris Papailiopoulos: AI shrinks distance between question and first answer",
    "description": "Dimitris Papailiopoulos shared his experience using Claude Code for research. He now has 'a magic box' where he throws in a question and gets a first answer basically for free in terms of human effort. Previously, exploring new ideas required either doing it himself or asking a student to run quick signal tests. Now he can explore initial signals without taking up anyone else's time - just him, Claude Code, and a few days of GPU time.",
    "author": "Dimitris Papailiopoulos",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Feb/17/research-claude-code/",
    "published_date": "2026-02-17",
    "topics": ["research", "ai", "llms", "coding-agents", "claude-code"],
    "type": "opinion"
  }
]
