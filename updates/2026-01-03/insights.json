[
  {
    "title": "Claude Code has the potential to transform all of tech",
    "description": "Ben Werdmuller predicts a real split in the tech industry between people who are outcome-driven (excited to test work with users faster) and people who are process-driven (get meaning from engineering itself and upset about having that taken away). Claude Code is seen as a catalyst for this divide.",
    "author": "Ben Werdmuller (quoted by Simon Willison)",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/2/ben-werdmuller/",
    "published_date": "2026-01-02",
    "topics": ["Claude Code", "AI coding", "outcome-driven vs process-driven", "industry transformation", "developer psychology"],
    "type": "opinion"
  },
  {
    "title": "Introducing gisthost.github.io",
    "description": "Simon forked gistpreview.github.io to create gisthost.github.io with two new features: workaround for Substack mangling URLs, and ability to serve larger files that get truncated in the JSON API. Also removed dependencies (jQuery, Bootstrap, fetch polyfill) and inlined JavaScript. The tool enables serving HTML files from GitHub Gists and integrates with Simon's claude-code-transcripts project.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/1/gisthost/",
    "published_date": "2026-01-01",
    "topics": ["GitHub Gists", "HTML hosting", "developer tools", "open source", "web development", "Claude Code integration"],
    "type": "technical"
  },
  {
    "title": "2025: The year in LLMs",
    "description": "Comprehensive annual review covering 26 major trends including: the year of 'reasoning', agents, coding agents and Claude Code, LLMs on the command-line, YOLO and normalization of deviance, $200/month subscriptions, top-ranked Chinese open weight models, long tasks, prompt-driven image editing, models winning academic competitions, Llama losing its way, OpenAI losing their lead, Gemini's rise, vibe coding, MCP, AI-enabled browsers, local models getting good, and 'slop'. Simon also notes he built 110 tools this year.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2025/Dec/31/the-year-in-llms/",
    "published_date": "2025-12-31",
    "topics": ["LLM", "AI agents", "coding agents", "Claude Code", "vibe coding", "MCP", "AI trends", "open source models", "command-line tools", "AI annual review"],
    "type": "technical"
  },
  {
    "title": "OpenAI Codex cloud rebranded to Codex web",
    "description": "OpenAI quietly rebranded 'Codex cloud' (cloud version of their coding agent) to 'Codex web' in late December 2025. The change aligns documentation with how users refer to it, differentiating between 'cloud tasks' (hosted runtime with GitHub, Slack, Linear integrations) and 'codex web' (the web app). Anthropic's equivalent is called 'Claude Code on the web'.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonw.substack.com/p/2025-the-year-in-llms",
    "published_date": "2025-12-31",
    "topics": ["OpenAI", "Codex", "rebranding", "AI coding agents", "cloud vs web"],
    "type": "technical"
  },
  {
    "title": "Language models change programmers from code writers to context managers",
    "description": "Liz Fong-Jones explains that LLMs transform programmers from writing lines of code to managing model context: pruning irrelevant things, adding useful material to context, and writing detailed specifications. Compares AI to an intern who read every textbook but has 0 practical experience with your codebase and forgets anything but the most recent hour of context.",
    "author": "Liz Fong-Jones (quoted by Simon Willison)",
    "source": "Blog",
    "url": "https://simonwillison.net/2025/Dec/30/liz-fong-jones/",
    "published_date": "2025-12-30",
    "topics": ["LLM", "AI coding", "context management", "prompt engineering", "AI-assisted programming", "developer workflow"],
    "type": "opinion"
  },
  {
    "title": "Jevons paradox is coming to knowledge work",
    "description": "Aaron Levie argues that by making tasks far cheaper, AI will ultimately lead to doing far more. The vast majority of AI tokens will be used on things workers don't do today: software projects that wouldn't have been started, contracts that wouldn't have been reviewed, medical research that wouldn't have been discovered, and marketing campaigns that wouldn't have launched.",
    "author": "Aaron Levie (quoted by Simon Willison)",
    "source": "Blog",
    "url": "https://simonw.substack.com/p/2025-the-year-in-llms",
    "published_date": "2025-12-29",
    "topics": ["AI", "Jevons paradox", "knowledge work", "productivity", "AI economics", "future of work"],
    "type": "opinion"
  },
  {
    "title": "The hard part of programming is knowing what to ask for",
    "description": "Jason Gorman notes the hard part isn't expressing what we want in code - it's turning human thinking with ambiguity and contradictions into computational thinking that's logically precise. This was true with punch cards, COBOL, and Visual Basic, and remains true when prompting language models. The hard part continues to be knowing exactly what to ask for.",
    "author": "Jason Gorman (quoted by Simon Willison)",
    "source": "Blog",
    "url": "https://simonw.substack.com/p/2025-the-year-in-llms",
    "published_date": "2025-12-29",
    "topics": ["programming", "AI coding", "computational thinking", "requirements", "software development philosophy"],
    "type": "opinion"
  }
]