[
  {
    "title": "Scaling LLMs to Larger Codebases",
    "description": "Comprehensive Hacker News discussion (307 points) about LLM workflows for handling larger codebases as of December 2025. Key insights include: 1) Effective framework: Research → Plan → Clear → Execute Plan → Review & Test, 2) Sonnet/Opus and GPTCodex can now fire off subagents during exploration, 3) Claude Code emerges as first convincing LLM Agent that runs locally, 4) Models still struggle with basic instruction following occasionally, 5) Importance of breaking projects into smaller parts using libraries for better AI context management.",
    "author": "kierangill.xyz / Hacker News Community",
    "source": "HN",
    "url": "https://news.ycombinator.com/item?id=46354970",
    "published_date": "2025-12-22",
    "topics": ["LLM", "AI Coding", "Claude Code", "Codebase Management", "Agent Workflows", "Context Engineering"],
    "type": "discussion"
  },
  {
    "title": "AWS CEO: Replacing Junior Devs with AI is 'One of the Dumbest Ideas'",
    "description": "Matt Garman, AWS CEO, criticizes replacing junior developers with AI in a December 2025 interview. Key points: 1) Juniors are often the most experienced with AI tools, 2) They're the least expensive, so cost optimization arguments don't hold, 3) Eliminating talent pipeline breaks the future of the organization, 4) Juniors provide unique value by asking 'dumb questions' that reveal abstractions are nonsense. Extensive Hacker News discussion (1070 points) exploring implications for talent development, company culture, and the future of software engineering careers.",
    "author": "Matt Garman / AWS / Hacker News Community",
    "source": "HN",
    "url": "https://news.ycombinator.com/item?id=46302267",
    "published_date": "2025-12-19",
    "topics": ["AI", "Junior Developers", "Talent Pipeline", "AWS", "Software Engineering Careers", "Company Culture"],
    "type": "discussion"
  },
  {
    "title": "2025 LLM Year in Review: Reinforcement Learning from Verifiable Rewards",
    "description": "Andrej Karpathy's comprehensive review of 2025 LLM developments highlighting RLVR (Reinforcement Learning from Verifiable Rewards) as the major new paradigm. Covers 6 paradigm shifts: 1) RLVR emergence, 2) Ghosts vs Animals/Jagged Intelligence, 3) Cursor as new LLM app layer, 4) Claude Code as AI that lives on your computer, 5) Vibe Coding as new programming paradigm, 6) Google Gemini Nano banana as hint of LLM GUI. Karpathy notes we're 'summoning ghosts' not 'growing animals' and discusses the unique characteristics of AI intelligence.",
    "author": "Andrej Karpathy",
    "source": "Blog",
    "url": "https://karpathy.bearblog.dev/year-in-review-2025/",
    "published_date": "2025-12-19",
    "topics": ["LLM", "Reinforcement Learning", "RLVR", "AI Research", "Year in Review", "Claude Code", "Vibe Coding"],
    "type": "technical"
  },
  {
    "title": "Semi-Supervised Learning for Large Language Models",
    "description": "ArXiv paper submission exploring semi-supervised learning approaches for training large language models. Addresses challenges in LLM training efficiency and effectiveness through hybrid learning methodologies.",
    "author": "ArXiv Contributors",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2512.21107",
    "published_date": "2025-12-24",
    "topics": ["LLM", "Semi-Supervised Learning", "Machine Learning", "Research"],
    "type": "technical"
  },
  {
    "title": "Formal Verification of Neural Networks with Early Exits",
    "description": "ArXiv paper addressing the intersection of efficiency and safety in neural networks through formal verification techniques for models with early exit capabilities. Critical for AI safety in production systems.",
    "author": "ArXiv Contributors",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2512.20755",
    "published_date": "2025-12-23",
    "topics": ["Neural Networks", "Formal Verification", "Safety", "AI Safety"],
    "type": "technical"
  },
  {
    "title": "RevFFN: Memory-Efficient Full-Parameter Fine-Tuning",
    "description": "ArXiv paper presenting RevFFN, a new approach for memory-efficient full-parameter fine-tuning of large language models. Addresses key challenge of memory constraints in LLM adaptation.",
    "author": "ArXiv Contributors",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2512.20920",
    "published_date": "2025-12-25",
    "topics": ["LLM", "Fine-Tuning", "Memory Efficiency", "Optimization"],
    "type": "technical"
  },
  {
    "title": "The Most Important AI Stories This Week",
    "description": "AI Explained YouTube video covering major AI developments from December 22, 2025. Topics include Google Flash, Amazon's AI moves, OpenAI fundraising developments, and Bernie Sanders' proposed moratorium on data center construction. Provides weekly roundup of significant AI industry news.",
    "author": "AI Explained",
    "source": "YouTube",
    "url": "https://www.youtube.com/watch?v=z50UOrFJDgo",
    "published_date": "2025-12-22",
    "topics": ["AI News", "Google", "Amazon", "OpenAI", "Policy"],
    "type": "discussion"
  },
  {
    "title": "The Download: AI Doomers and Tech Developments",
    "description": "MIT Technology Review's daily newsletter covering technology developments including AI news and analysis from December 19, 2025. Part of ongoing coverage of AI's impact on technology and society.",
    "author": "MIT Technology Review",
    "source": "TechMedia",
    "url": "https://www.technologyreview.com/2025/12/19/1130167/the-download-chinas-dying-ev-batteries-and-why-ai-doomers-are-doubling-down/",
    "published_date": "2025-12-19",
    "topics": ["AI", "Technology", "Newsletter", "Daily News"],
    "type": "discussion"
  }
]