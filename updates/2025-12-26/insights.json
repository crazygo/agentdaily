[
  {
    "title": "2025 LLM Year in Review",
    "description": "Andrej Karpathy publishes his comprehensive 2025 review of LLM developments, highlighting the emergence of Reinforcement Learning from Verifiable Rewards (RLVR) as a major new paradigm in LLM development. The review covers 6 major paradigm shifts that changed AI in 2025.",
    "author": "Andrej Karpathy",
    "source": "Blog",
    "url": "https://karpathy.bearblog.dev/year-in-review-2025/",
    "published_date": "2025-12-19",
    "topics": ["LLM", "Reinforcement Learning", "RLVR", "AI Research", "Year in Review"],
    "type": "technical"
  },
  {
    "title": "The Most Important AI Stories This Week",
    "description": "AI Explained covers the week's major AI developments including Google Flash, Amazon's AI moves, OpenAI fundraising developments, and Bernie Sanders' proposed moratorium on data center construction.",
    "author": "AI Explained",
    "source": "YouTube",
    "url": "https://www.youtube.com/watch?v=z50UOrFJDgo",
    "published_date": "2025-12-22",
    "topics": ["AI News", "Google", "Amazon", "OpenAI", "Policy"],
    "type": "discussion"
  },
  {
    "title": "The Download: China's dying EV batteries, and why AI doomers are doubling down",
    "description": "MIT Technology Review's daily newsletter covering technology developments including AI news and analysis from December 19, 2025.",
    "author": "MIT Technology Review",
    "source": "TechMedia",
    "url": "https://www.technologyreview.com/2025/12/19/1130167/the-download-chinas-dying-ev-batteries-and-why-ai-doomers-are-doubling-down/",
    "published_date": "2025-12-19",
    "topics": ["AI", "Technology", "Newsletter", "Daily News"],
    "type": "discussion"
  },
  {
    "title": "Semi-Supervised Learning for Large Language Models",
    "description": "ArXiv paper submission exploring semi-supervised learning approaches for training large language models, submitted on December 24, 2025.",
    "author": "ArXiv Contributors",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2512.21107",
    "published_date": "2025-12-24",
    "topics": ["LLM", "Semi-Supervised Learning", "Machine Learning", "Research"],
    "type": "technical"
  },
  {
    "title": "Formal Verification of Neural Networks with Early Exits",
    "description": "ArXiv paper addressing the intersection of efficiency and safety in neural networks through formal verification techniques for models with early exit capabilities.",
    "author": "ArXiv Contributors",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2512.20755",
    "published_date": "2025-12-23",
    "topics": ["Neural Networks", "Formal Verification", "Safety", "AI Safety"],
    "type": "technical"
  },
  {
    "title": "RevFFN: Memory-Efficient Full-Parameter Fine-Tuning",
    "description": "ArXiv paper presenting RevFFN, a new approach for memory-efficient full-parameter fine-tuning of large language models.",
    "author": "ArXiv Contributors",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2512.20920",
    "published_date": "2025-12-25",
    "topics": ["LLM", "Fine-Tuning", "Memory Efficiency", "Optimization"],
    "type": "technical"
  },
  {
    "title": "Coding with LLMs in the summer of 2025 â€“ an update",
    "description": "Hacker News discussion focused on local AI inference for coding, discussing improvements in hardware/frameworks that are making local LLM coding more accessible despite memory and price constraints.",
    "author": "Hacker News Community",
    "source": "HN",
    "url": "https://news.ycombinator.com/item?id=44623953",
    "published_date": "2025-12-20",
    "topics": ["AI Coding", "LLM", "Local Inference", "Hardware"],
    "type": "discussion"
  }
]
