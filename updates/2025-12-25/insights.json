[
  {
    "title": "Holistic Evaluation of State-of-the-Art LLMs for Code Generation",
    "description": "Comprehensive empirical evaluation of six state-of-the-art LLMs (DeepSeek-R1, GPT-4.1, Claude-3.7, DeepSeek-V3, Qwen2.5-Coder, Llama-3.3) for code generation using 944 LeetCode problems across five languages. Key findings: 1) DeepSeek-R1 and GPT-4.1 consistently outperform others in correctness, efficiency, and robustness; 2) Python3 and JavaScript have fewer compile/runtime errors; 3) Algorithmic suboptimality is common, especially in Llama-3.3; 4) Explicit optimization prompts can significantly improve performance; 5) Even top models occasionally fail on complex problems, underscoring need for human oversight. The study echoes Acemoglu's view that current AI will automate only ~5% of tasks and advocates for pro-human AI deployment: 'IA >> AI' - intelligence amplification outperforms artificial intelligence alone.",
    "author": "Anonymous Authors (Iowa State University)",
    "source": "ArXiv",
    "url": "https://arxiv.org/abs/2512.18131",
    "published_date": "2025-12-18",
    "topics": ["LLM", "Code Generation", "Benchmarking", "LeetCode", "DeepSeek-R1", "GPT-4.1", "Evaluation", "AI Assistants"],
    "type": "technical"
  },
  {
    "title": "What a Year for AI Coding",
    "description": "A developer with almost three decades of experience reflects on the dramatic evolution of AI coding in 2025. At the start of 2025, LLMs were 'very sketchy, creating as many problems as they solved.' By December 2025, the author is confident that 'the best coding LLMs are better than 95% of software developers out there.' While noting that mistakes still happen (as with humans), the author states we're not quite at 100% outsourcing yet but the strides made in a single year are 'truly amazing' and anticipates even more progress by the end of 2026.",
    "author": "Reddit User (r/vibecoding)",
    "source": "Reddit",
    "url": "https://www.reddit.com/r/vibecoding/comments/1ppr1kc/what_a_year/",
    "published_date": "2025-12-18",
    "topics": ["AI Coding", "LLM Progress", "Developer Experience", "2025 Review", "Vibe Coding", "Industry Adoption"],
    "type": "discussion"
  },
  {
    "title": "Your Job is to Deliver Code You Have Proven to Work",
    "description": "Simon Willison argues that AI-assisted developers must deliver proven code, not just generate it. The piece critiques junior engineers who submit giant untested PRs expecting code review to catch issues. Willison outlines two essential steps: 1) Manual testing - actually seeing the code work, with terminal commands or screen captures as proof; 2) Automated testing - now easier with LLMs. For coding agents like Claude Code, developers must ensure they prove changes work through testing. The key insight: 'Almost anyone can prompt an LLM to generate a thousand-line patch. That's no longer valuable. What's valuable is contributing code that is proven to work.'",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2025/Dec/18/code-proven-to-work/",
    "published_date": "2025-12-18",
    "topics": ["AI Coding", "Code Quality", "Testing", "LLM Best Practices", "Developer Responsibility", "Coding Agents"],
    "type": "opinion"
  },
  {
    "title": "Browser Agent Success Story",
    "description": "First successful use of a browser agent (Claude in Chrome extension) to solve a real problem - finding CORS configuration in Cloudflare dashboard. Took 1m45s to find the exact solution. Despite concerns about prompt injection risks, this was a very positive experience.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2025/Dec/22/",
    "published_date": "2025-12-22",
    "topics": ["Browser Agents", "Claude", "Chrome Extension", "CORS", "Cloudflare", "Prompt Injection"],
    "type": "discussion"
  },
  {
    "title": "Cooking with Claude - LLMs for Culinary Tasks",
    "description": "Simon Willison describes using LLMs for cooking, evolving from basic recipes to advanced tasks. Successfully had Claude vibe-code a custom application to help with timing for complicated meal preparation. Demonstrates practical LLM use beyond coding.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2025/Dec/23/",
    "published_date": "2025-12-23",
    "topics": ["LLM Applications", "Claude", "Vibe Coding", "Practical AI", "Cooking"],
    "type": "opinion"
  },
  {
    "title": "MicroQuickJS for Safe Sandboxing",
    "description": "Fabrice Bellard's MicroQuickJS is a JavaScript engine for embedded systems (10 kB RAM, 100 kB ROM). Simon used Claude Code to investigate it as a safe sandboxing environment for untrusted code from LLMs. Found it very well-suited with robust memory/time limits, no dangerous primitives, and regex engine protecting against exhaustion attacks.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2025/Dec/23/",
    "published_date": "2025-12-23",
    "topics": ["Sandboxing", "JavaScript", "LLM Safety", "MicroQuickJS", "Fabrice Bellard", "WebAssembly"],
    "type": "technical"
  },
  {
    "title": "2025 LLM Year in Review",
    "description": "Andrej Karpathy's comprehensive review of paradigm shifts in LLMs during 2025, covering: 1) RLVR (Reinforcement Learning from Verifiable Rewards) as a new training stage alongside pretraining, SFT, and RLHF; 2) Understanding LLMs as 'ghosts' not 'animals' - with jagged intelligence profiles; 3) Cursor and the new layer of LLM applications; 4) Claude Code as the first convincing LLM agent that runs locally; 5) 'Vibe coding' - AI enabling programming through natural language; 6) Nano banana and the emergence of LLM GUIs beyond text chat. Karpathy states we haven't unlocked 10% of LLM potential yet.",
    "author": "Andrej Karpathy",
    "source": "Blog",
    "url": "https://karpathy.bearblog.dev/year-in-review-2025/",
    "published_date": "2025-12-19",
    "topics": ["LLM", "RLVR", "AI Agents", "Vibe Coding", "Claude Code", "Machine Learning", "AI Paradigms"],
    "type": "opinion"
  },
  {
    "title": "Agent Skills Open Standard",
    "description": "Anthropic has turned their skills mechanism into an 'open standard' living in an independent agentskills/agentskills GitHub repository. The specification is tiny but deliberately under-specified. Adoption promoted by OpenCode, Cursor, Amp, Letta, goose, GitHub, and VS Code. OpenAI added Skills to Codex documentation on Dec 20.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2025/Dec/19/",
    "published_date": "2025-12-19",
    "topics": ["Agent Skills", "Anthropic", "OpenAI", "AI Agents", "Standards", "Codex"],
    "type": "opinion"
  },
  {
    "title": "GPT-5.2-Codex Release",
    "description": "OpenAI released GPT-5.2-Codex, optimized for agentic coding with improvements on long-horizon work through context compaction, stronger performance on large code changes, improved Windows performance, and enhanced cybersecurity capabilities. Scores 64% on Terminal-Bench 2.0. Features invite-only preview for cybersecurity professionals.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2025/Dec/19/",
    "published_date": "2025-12-19",
    "topics": ["OpenAI", "GPT-5.2-Codex", "Coding Agents", "Terminal-Bench", "Cybersecurity"],
    "type": "opinion"
  },
  {
    "title": "The State of AI Coding Report 2025",
    "description": "Hacker News discussion on the state of AI coding in 2025. An AI code review agent used by 2,000 companies from startups like PostHog, Brex, and Partiful to F500s and F10s shared insights about approximately a billion lines of code reviewed. Discussion covers the current state and effectiveness of AI coding tools.",
    "author": "Hacker News Community",
    "source": "Hacker News",
    "url": "https://news.ycombinator.com/item?id=46301886",
    "published_date": "2025-12-19",
    "topics": ["AI Coding", "Code Review", "Industry Report", "LLM Agents", "Startups"],
    "type": "discussion"
  },
  {
    "title": "A Guide to Local Coding Models",
    "description": "Hacker News discussion comparing local coding models. Notes that OpenAI's Codex is charged significantly lower than Claude, with suggestions that $100-200/month is worth it for serious developers. Discussion covers the trade-offs between local and cloud-based coding models.",
    "author": "Hacker News Community",
    "source": "Hacker News",
    "url": "https://news.ycombinator.com/item?id=46348329",
    "published_date": "2025-12-20",
    "topics": ["Local Models", "OpenAI Codex", "Claude", "Cost Analysis", "AI Coding"],
    "type": "discussion"
  },
  {
    "title": "LLM Year in Review - Hacker News Discussion",
    "description": "Hacker News discussion on Andrej Karpathy's 2025 LLM Year in Review. Commenters highlight that Claude Code has catapulted their performance at least 5x, and with minimal cost for writing tests, they're able to achieve higher code quality. Discussion covers the practical impact of coding agents on developer productivity.",
    "author": "Hacker News Community",
    "source": "Hacker News",
    "url": "https://news.ycombinator.com/item?id=46330726",
    "published_date": "2025-12-20",
    "topics": ["LLM", "Claude Code", "Developer Productivity", "Karpathy", "AI Coding"],
    "type": "discussion"
  }
]
