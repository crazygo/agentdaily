[
  {
    "title": "A few random notes from Claude coding quite a bit last few weeks",
    "description": "Andrej Karpathy shares his dramatic shift in coding workflow: went from 80% manual+autocomplete and 20% agents in November 2025 to 80% agents and 20% edits+touchups by December 2025. Describes this as 'easily the biggest change to my basic coding workflow in ~2 decades of programming.' Key insights: (1) LLMs make subtle conceptual errors similar to sloppy junior devs; (2) They don't manage confusion, seek clarifications, or push back appropriately; (3) They overcomplicate code and APIs, bloating abstractions; (4) Despite issues, it's a 'net huge improvement' and difficult to imagine going back to manual coding; (5) LLMs excel at 'tenacity' - never getting tired or demoralized, working relentlessly until success; (6) Main benefit isn't just speedup but expansion - doing things that weren't worth coding before and approaching code that was previously inaccessible due to knowledge/skill gaps. Predicts 2026 as the 'Slopacolypse' across GitHub, Substack, ArXiv, and digital media. Notes he's starting to atrophy his manual coding ability.",
    "author": "Andrej Karpathy",
    "source": "Twitter",
    "url": "https://x.com/karpathy/status/2015883857489522876",
    "published_date": "2026-01-30",
    "topics": ["AI coding", "LLM workflow", "Claude Code", "agentic coding", "software engineering", "productivity", "code generation", "technical debt"],
    "type": "opinion"
  },
  {
    "title": "Tips for getting coding agents to write good Python tests",
    "description": "Simon Willison shares practical advice on getting coding agents to write quality tests. Key recommendations: (1) Python helps due to abundant pytest examples in training data; (2) Can use specific instructions like 'use pytest-httpx to mock endpoints' and Claude understands; (3) Watch for anti-patterns like duplicated test setup code - push back with 'refactor to use pytest.mark.parametrize' and 'extract common setup into fixture'; (4) Best way is to ensure agents work in projects with existing test suites using good patterns - they pick up patterns without extra prompting; (5) Once a project has clean basic tests, new tests added by agents tend to match in quality; (6) Quick tip: Clone reference projects and have agent imitate their testing patterns. Emphasizes that coding agents learn from existing code patterns just like working with human developers.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/26/tests/",
    "published_date": "2026-01-26",
    "topics": ["AI coding", "testing", "pytest", "coding agents", "Python", "code quality", "best practices"],
    "type": "tutorial"
  },
  {
    "title": "State of AI in 2026: LLMs, Coding, Scaling Laws, China, Agents, GPUs, AGI",
    "description": "Lex Fridman Podcast episode #490 featuring Nathan Lambert and Sebastian Raschka discussing the comprehensive state of AI in 2026. Topics covered include large language models (LLMs), AI coding and programming transformations, scaling laws, China's role in AI development, AI agents, GPU infrastructure, and AGI progress. The episode provides a high-level overview of AI trends and breakthroughs as we enter 2026, with specific focus on how AI coding is evolving and impacting software development.",
    "author": "Lex Fridman, Nathan Lambert, Sebastian Raschka",
    "source": "Podcast",
    "url": "https://www.youtube.com/watch?v=EV7WhVT270Q",
    "published_date": "2026-01-31",
    "topics": ["AI state of the art", "LLMs", "AI coding", "scaling laws", "AI agents", "AGI", "GPUs", "China AI"],
    "type": "discussion"
  },
  {
    "title": "How to Apply Agentic Coding to Solve Problems",
    "description": "Eivind Kjosbakken shares a three-step framework for solving problems with Claude Code: (1) Discover and prioritize problems by giving the agent access to all relevant data (logs, CRM, GitHub, etc.); (2) Come up with solutions using value-effort analysis; (3) Execute solutions through iterative prompting and review. Emphasizes that coding agents are most effective when given liberal access to the same tools humans use, with proper security constraints. Notes that over 50% of production problems can be solved with simple prompts. The article demonstrates how agentic coding can dramatically improve debugging and problem-solving speed when agents have appropriate tool access.",
    "author": "Eivind Kjosbakken",
    "source": "Towards Data Science",
    "url": "https://towardsdatascience.com/how-to-apply-agentic-coding-to-solve-problem/",
    "published_date": "2026-01-31",
    "topics": ["agentic coding", "Claude Code", "problem-solving", "AI agents", "production debugging", "workflow", "tool access"],
    "type": "tutorial"
  },
  {
    "title": "The Unbearable Lightness of Coding",
    "description": "Elena Jolkver confesses to building a full RAG retrieval system with embeddings, hybrid search, and GUI in 25 hours using AI, then facing a 'technical debt hangover' when trying to debug it a month later. Explores the trade-offs of 'vibe coding': insane speed and productivity vs. losing implementation intimacy and understanding. Describes the shift from craftsman to conductor, from builder to project lead, noting that 'the code belongs to the machine' while the design and responsibility remain human. The article questions whether this new way of coding is sustainable or if we're creating generations of developers who don't understand what they're building.",
    "author": "Elena Jolkver",
    "source": "Towards Data Science",
    "url": "https://towardsdatascience.com/the-unbearable-lightness-of-coding/",
    "published_date": "2026-01-29",
    "topics": ["vibe coding", "AI productivity", "technical debt", "GitHub Copilot", "software engineering trade-offs", "code understanding"],
    "type": "opinion"
  },
  {
    "title": "AI2: Open Coding Agents - Hacker News Discussion",
    "description": "Hacker News discussion on AI2's release of fully open coding agents. Key discussion points: (1) Shift in terminology - bare LLMs are now being called 'agents' directly, whereas 'agent' used to mean LLM + scaffolding; (2) More accurate term is 'agentic LLMs' - models purpose-built with agent-specific RL and fine-tuned for reasoning and tool calling; (3) AI2's models are fully open - including model, weights, training pipeline, inference stack, and corpus, unlike Meta's open-weight but closed-training-data approach; (4) Debates about evaluation methodology - some claims ignore Meta CWM models' performance; (5) Practical discussion about fine-tuning on local repos vs. context management - most commenters agree intelligently managing context with frontier models beats fine-tuning smaller models; (6) Fine-tuning coding models not nearly as effective as good context management; (7) One commenter working on 'biggest codebase in the world' reports fine-tuned model doesn't produce better code than non-tuned - 99% of improvements can be gleaned from context/nearby code; (8) Inference cost and VRAM constraints are the real bottlenecks - 32B model requires dual 3090s or A6000 even at 4-bit quantization.",
    "author": "Hacker News Community",
    "source": "Hacker News",
    "url": "https://news.ycombinator.com/item?id=46783017",
    "published_date": "2026-01-27",
    "topics": ["AI coding agents", "open source", "fine-tuning", "context management", "LLMs", "SWE-bench", "inference costs", "model evaluation"],
    "type": "discussion"
  },
  {
    "title": "Moltbook is the most interesting place on the internet right now",
    "description": "Simon Willison explores OpenClaw (formerly Clawdbot/Moltbot), an open-source digital personal assistant with over 114,000 GitHub stars. He covers Moltbook, a social network where AI agents interact, share skills via clawhub.ai, and discuss topics like Android automation and security concerns. The article highlights the enormous value being unlocked despite security risks, and questions when a safe version will be built. Willison notes the fascinating emergence of agent-to-agent communication and the rapid pace of development in AI agent ecosystems.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/30/moltbook/",
    "published_date": "2026-01-30",
    "topics": ["AI agents", "OpenClaw", "Moltbook", "AI automation", "security", "prompt injection", "agent-to-agent communication"],
    "type": "technical"
  }
]
