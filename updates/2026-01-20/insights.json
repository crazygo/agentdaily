[
  {
    "title": "Agents using CLI tools in place of REST APIs",
    "description": "Simon Willison discusses why AI agents are better off using CLI tools instead of REST APIs: to save on context window, improve accuracy and success rate when multiple tool calls are involved (particularly for pagination, rate-limit backoff, authentication failures), and lower the bar so cheap/fast models (gpt-5-nano, haiku-4.5) can reliably succeed. Using raw APIs is something only costly strong models (gpt-5.2, opus-4.5) can manage.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/17/",
    "published_date": "2026-01-17",
    "topics": ["AI agents", "CLI tools", "API design", "context window", "model capabilities"],
    "type": "technical"
  },
  {
    "title": "Is More Context Always Better? Examining LLM Reasoning for Time Interval Prediction",
    "description": "Researchers at Amazon (Cao et al.) study LLM capabilities in predicting time intervals between recurring user actions. Key findings: LLMs surpass lightweight statistical baselines but consistently underperform dedicated ML models, showing limited ability to capture quantitative temporal structure. Moderate context improves accuracy, but adding further user-level detail degrades performance, challenging the assumption that 'more context leads to better reasoning'. Accepted at WWW 2026.",
    "author": "Yanan Cao, Farnaz Fallahi, et al.",
    "source": "ArXiv",
    "url": "https://arxiv.org/abs/2601.10132",
    "published_date": "2026-01-15",
    "topics": ["LLM reasoning", "context window", "temporal prediction", "model limitations"],
    "type": "technical"
  },
  {
    "title": "Open Responses: Vendor-neutral LLM API specification",
    "description": "Simon Willison highlights the Open Responses initiative, a vendor-neutral specification for the JSON API that clients can use to talk to hosted LLMs. Derived from OpenAI's Responses API, it includes launch partners like OpenRouter, Hugging Face, LM Studio, vLLM, Ollama, and Vercel. Simon emphasizes the need for comprehensive, language-independent conformance test suites for both servers and clients.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/15/open-responses/",
    "published_date": "2026-01-15",
    "topics": ["Open Responses", "API standards", "LLM interoperability", "conformance testing"],
    "type": "opinion"
  },
  {
    "title": "Claude Cowork Exfiltrates Files via API Domain",
    "description": "Security researchers at Prompt Armor discovered a prompt injection vulnerability in Claude Cowork. By including an attacker's Anthropic API key in malicious content, they could trick the agent into uploading files it could see to api.anthropic.com/v1/files endpoint, bypassing outbound HTTP restrictions. This highlights the ongoing challenge of securing AI agents against prompt injection attacks.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/14/claude-cowork-exfiltrates-files/",
    "published_date": "2026-01-14",
    "topics": ["security", "prompt injection", "AI agents", "data exfiltration", "Claude Cowork"],
    "type": "technical"
  },
  {
    "title": "LLM-Based Agentic Systems for Software Engineering: Challenges and Opportunities",
    "description": "Yongjian Tang and Thomas Runkler present a systematic review of LLM-based multi-agent systems across the Software Development Life Cycle (SDLC). The paper covers requirements engineering, code generation, static code checking, testing, and debugging. It identifies key challenges in multi-agent orchestration, human-agent coordination, computational cost optimization, and effective data collection. Accepted to GenSE 2026 workshop.",
    "author": "Yongjian Tang, Thomas Runkler",
    "source": "ArXiv",
    "url": "https://arxiv.org/abs/2601.09822",
    "published_date": "2026-01-14",
    "topics": ["LLM agents", "software engineering", "multi-agent systems", "SDLC", "research"],
    "type": "technical"
  },
  {
    "title": "Anthropic invests $1.5 million in Python Software Foundation",
    "description": "Anthropic announced a two-year partnership with the Python Software Foundation (PSF) contributing $1.5 million to support Python ecosystem security, including crucial security advances to CPython and PyPI, sustaining the PSF's core work supporting the Python language, ecosystem, and global community through the Developer in Residence program.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/13/anthropic-python-foundation/",
    "published_date": "2026-01-13",
    "topics": ["Python", "open source", "security", "Anthropic", "PSF"],
    "type": "opinion"
  }
]
