[
  {
    "title": "Wilson Lin on FastRender: a browser built by thousands of parallel agents",
    "description": "Simon Willison interviews Wilson Lin about FastRender, a web browser built from scratch using Cursor's multi-agent harness. Key insights: 2,000 agents running concurrently making thousands of commits per hour; project has nearly 30,000 commits; agents ran autonomously for a week without human intervention; GPT-5.1 and GPT-5.2 general models worked better than coding specialist models; intermittent errors are acceptable to maintain high throughput; agents self-selected dependencies like Skia, HarfBuzz, and Taffy; uses git submodules for specifications to provide feedback loops.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/23/fastrender/",
    "published_date": "2026-01-23",
    "topics": ["multi-agent systems", "autonomous coding", "browser rendering", "Cursor", "FastRender", "LLM agents"],
    "type": "technical"
  },
  {
    "title": "Context is AI coding's real bottleneck in 2026",
    "description": "Article discussing how the context gap determines AI productivity gains in coding. Explores the challenge of providing sufficient context to AI coding assistants for effective code generation and modification.",
    "author": "The New Stack",
    "source": "TechMedia",
    "url": "https://thenewstack.io/context-is-ai-codings-real-bottleneck-in-2026/",
    "published_date": "2026-01-23",
    "topics": ["AI coding", "context window", "productivity", "bottlenecks"],
    "type": "technical"
  },
  {
    "title": "Show HN: yolo-cage â€“ AI coding agents that can't exfiltrate secrets",
    "description": "Hacker News Show HN post presenting yolo-cage, a tool for sandboxing AI coding agents to prevent secret exfiltration. Addresses security concerns around autonomous AI coding systems.",
    "author": "Hacker News community",
    "source": "HN",
    "url": "https://news.ycombinator.com/front?day=2026-01-21",
    "published_date": "2026-01-21",
    "topics": ["AI security", "sandboxing", "secret management", "agent safety"],
    "type": "technical"
  },
  {
    "title": "Three types of LLM workloads",
    "description": "Hacker News discussion categorizing LLM workloads into different types, discussing how to optimize for each category in terms of infrastructure, cost, and performance.",
    "author": "Hacker News community",
    "source": "HN",
    "url": "https://news.ycombinator.com/front?day=2026-01-21",
    "published_date": "2026-01-21",
    "topics": ["LLM workloads", "infrastructure", "performance optimization"],
    "type": "discussion"
  },
  {
    "title": "google gemini3 absolutely SMOKES qwen3 coder",
    "description": "Reddit r/artificial discussion about building 'Gemini Coder' for free AI coding using web chats like AI Studio, DeepSeek, or Open WebUI, comparing performance of different coding-focused LLMs.",
    "author": "Reddit r/artificial",
    "source": "Reddit",
    "url": "https://www.reddit.com/r/artificial/comments/1qj3e0z/google_gemini3_absolutely_smokes_qwen3_coder/",
    "published_date": "2026-01-20",
    "topics": ["Gemini", "Qwen", "coding LLMs", "model comparison"],
    "type": "discussion"
  },
  {
    "title": "10 things I learned from burning myself out with AI coding agents",
    "description": "Benj Edwards shares insights from 50+ AI coding projects using Claude Code and Claude Opus 4.5 over two months. Key learnings: (1) People remain necessary - AI amplifies expertise rather than replacing it; (2) AI models are brittle beyond training data - great at modern web tech, terrible at 6502 Assembly; (3) True novelty is challenging - semantic associations in LLMs can cause 'preconceived notions' that block innovation; (4) The '90 percent problem' - first 90% comes fast, last 10% is tedious; (5) Feature creep becomes irresistible; (6) AGI is not here yet - models can't learn permanently; (7) Even 'fast' isn't fast enough; (8) People may become busier than ever, not unemployed; (9) Fast is scary to people; (10) These tools aren't going away. Created over 50 demo projects including multiplayer games and emulators. AI agents are tools that amplify human ideas, not autonomous employees.",
    "author": "Benj Edwards",
    "source": "TechMedia",
    "url": "https://arstechnica.com/information-technology/2026/01/10-things-i-learned-from-burning-myself-out-with-ai-coding-agents/",
    "published_date": "2026-01-19",
    "topics": ["AI coding", "Claude Code", "vibe coding", "agent limitations", "developer experience", "automation impact"],
    "type": "opinion"
  },
  {
    "title": "[D] Three AI news stories from this week",
    "description": "Reddit r/MachineLearning weekly AI news roundup mentioning Claude integration into Visual Studio Code and AI tools living inside editors as part of the week's notable developments.",
    "author": "Reddit r/MachineLearning",
    "source": "Reddit",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1qkwa50/d_three_ai_news_stories_from_this_week_that/",
    "published_date": "2026-01-19",
    "topics": ["AI news", "VS Code", "Claude integration", "editor tools"],
    "type": "opinion"
  },
  {
    "title": "Self-deploying AI agent: Watched it spend 6+ hours...",
    "description": "Reddit r/artificial post where user gave an AI coding agent a task to deploy itself to a VPS; it ran for 6+ hours with zero timeouts, demonstrating long-horizon autonomous task execution.",
    "author": "Reddit r/artificial",
    "source": "Reddit",
    "url": "https://www.reddit.com/r/artificial/comments/1qfkwgd/selfdeploying_ai_agent_watched_it_spend_6_hours/",
    "published_date": "2026-01-19",
    "topics": ["autonomous agents", "self-deployment", "VPS", "long-running tasks"],
    "type": "discussion"
  },
  {
    "title": "[R] I built a congestion-aware KV cache eviction system for LLMs",
    "description": "Reddit r/MachineLearning post focusing on improving LLM serving with better KV cache eviction strategies that are congestion-aware, optimizing memory usage during inference.",
    "author": "Reddit r/MachineLearning",
    "source": "Reddit",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1ql4kwa/r_i_built_a_congestionaware_kv_cache_eviction/",
    "published_date": "2026-01-19",
    "topics": ["KV cache", "LLM serving", "memory optimization", "inference"],
    "type": "technical"
  },
  {
    "title": "Android Studio Otter Boosts Agent Workflows and Adds LLM Flex",
    "description": "InfoQ article covering new AI-powered features in Android Studio including enhanced agent workflows and LLM Flex integration for developers.",
    "author": "InfoQ",
    "source": "TechMedia",
    "url": "https://www.infoq.com/news/2026/01/android-studio-otter-llm-flex/",
    "published_date": "2026-01-18",
    "topics": ["Android Studio", "AI workflows", "LLM integration", "developer tools"],
    "type": "technical"
  },
  {
    "title": "The recurring dream of replacing developers",
    "description": "Hacker News discussion on how AI-assisted coding is eliminating discrete units of programmer labor: boilerplate, CRUD endpoints, test scaffolding, and migrations. Community discusses the impact on developer roles.",
    "author": "Hacker News community",
    "source": "HN",
    "url": "https://news.ycombinator.com/item?id=46658345",
    "published_date": "2026-01-18",
    "topics": ["AI impact", "developer jobs", "automation", "boilerplate"],
    "type": "discussion"
  },
  {
    "title": "[P] What we learned building automatic failover for LLM providers",
    "description": "Reddit r/MachineLearning post covering building a gateway that tracks health metrics (success rates, response times, error patterns) for LLM providers and implements automatic failover mechanisms.",
    "author": "Reddit r/MachineLearning",
    "source": "Reddit",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1qk4xqj/p_what_we_learned_building_automatic_failover_for/",
    "published_date": "2026-01-18",
    "topics": ["LLM infrastructure", "failover", "health metrics", "production"],
    "type": "technical"
  },
  {
    "title": "[D] ICML26 LLM Review Policy",
    "description": "Reddit r/MachineLearning discussion about ICML 2026 policies allowing authors to decide whether LLMs can be used during paper reviews, exploring implications for academic peer review.",
    "author": "Reddit r/MachineLearning",
    "source": "Reddit",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1qg5ncu/d_icml26_llm_review_policy/",
    "published_date": "2026-01-18",
    "topics": ["LLM policy", "academic review", "ICML 2026", "peer review"],
    "type": "discussion"
  },
  {
    "title": "Fireship AI Coding Livestream",
    "description": "Fireship hosted an AI coding livestream checking out WordPress AI news and updates, discussing the latest developments in AI-powered coding tools.",
    "author": "Fireship",
    "source": "YouTube",
    "url": "https://www.youtube.com/watch?v=dmXhleA_eQ8",
    "published_date": "2026-01-17",
    "topics": ["AI coding", "WordPress AI", "livestream"],
    "type": "discussion"
  },
  {
    "title": "AI Week in Review 26.01.17",
    "description": "Weekly AI roundup covering the 'Ralph loop' in Claude Code for agentic coding tasks, along with other notable developments in AI coding and LLM technologies.",
    "author": "Patrick McGuinness",
    "source": "Blog",
    "url": "https://patmcguinness.substack.com/p/ai-week-in-review-260117",
    "published_date": "2026-01-17",
    "topics": ["AI news", "Claude Code", "Ralph loop", "agentic coding"],
    "type": "opinion"
  },
  {
    "title": "TencentCloudADP/youtu-agent: Agent Skills support inspired by Claude Code",
    "description": "GitHub project announcement for youtu-agent, a simple yet powerful agent framework with Agent Skills support, inspired by Anthropic's Claude Code. Announced on 2026-01-17.",
    "author": "TencentCloudADP",
    "source": "Platform",
    "url": "https://github.com/TencentCloudADP/youtu-agent",
    "published_date": "2026-01-17",
    "topics": ["AI agents", "Claude Code", "GitHub", "agent skills"],
    "type": "technical"
  },
  {
    "title": "Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion",
    "description": "arXiv paper (cs.AI) advancing In-Context Learning (ICL) from static to dynamic demonstration usage for mathematical reasoning tasks. Proposes methods for dynamically inserting demonstrations during inference.",
    "author": "arXiv researchers",
    "source": "Paper",
    "url": "https://arxiv.org/html/2601.11979v1",
    "published_date": "2026-01-17",
    "topics": ["in-context learning", "mathematical reasoning", "LLM training", "demonstrations"],
    "type": "technical"
  },
  {
    "title": "AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems",
    "description": "arXiv paper (cs.AI) presenting a framework for evaluating agentic LLM systems with verifiable metrics. Focuses on trustworthiness and control in autonomous agent systems.",
    "author": "arXiv researchers",
    "source": "Paper",
    "url": "https://arxiv.org/html/2601.11903v1",
    "published_date": "2026-01-17",
    "topics": ["agent evaluation", "verifiable metrics", "agentic LLM", "trustworthiness"],
    "type": "technical"
  },
  {
    "title": "ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents",
    "description": "arXiv paper (cs.AI) focusing on context management for information seeking agents with active and reflection-driven mechanisms for long-horizon tasks.",
    "author": "arXiv researchers",
    "source": "Paper",
    "url": "https://arxiv.org/html/2601.12030v1",
    "published_date": "2026-01-17",
    "topics": ["context management", "information seeking", "agent reflection", "long-horizon tasks"],
    "type": "technical"
  },
  {
    "title": "Embedding Retrofitting: Data Engineering for better RAG",
    "description": "arXiv paper discussing adjustments to pre-trained word vectors using knowledge graph constraints for better retrieval augmented generation (RAG) performance.",
    "author": "arXiv researchers",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2601.15298",
    "published_date": "2026-01-17",
    "topics": ["RAG", "embeddings", "knowledge graphs", "retrieval"],
    "type": "technical"
  },
  {
    "title": "[D] It feels like LLM inference is missing its AWS Lambda moment",
    "description": "Reddit r/MachineLearning discussion on why LLM inference doesn't fit the serverless model due to high cold start costs and process initialization challenges. Explores alternative architectures.",
    "author": "Reddit r/MachineLearning",
    "source": "Reddit",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1qfgqvy/dit_feels_like_llm_inference_is_missing_its_aws/",
    "published_date": "2026-01-17",
    "topics": ["LLM inference", "serverless", "cold starts", "infrastructure"],
    "type": "discussion"
  }
]
