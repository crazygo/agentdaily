[
  {
    "title": "2025: The year in LLMs",
    "description": "Comprehensive annual review of LLM developments in 2025, covering 26 major trends including: the year of reasoning (RLVR), agents, coding agents and Claude Code, LLMs on the command-line, YOLO mode and Normalization of Deviance, $200/month subscriptions, top-ranked Chinese open weight models (GLM-4.7, Kimi K2, DeepSeek V3.2), long tasks, prompt-driven image editing, models winning gold in academic competitions (IMO, ICPC), Llama losing its way, OpenAI losing their lead, Gemini's rise, pelicans riding bicycles, building 110 tools, the snitch phenomenon, vibe coding, MCP, alarmingly AI-enabled browsers, the lethal trifecta, programming on mobile phones, conformance suites, local vs cloud models, slop, and data center unpopularity. Key insight: 'The length of tasks AI can do is doubling every 7 months' according to METR. Anthropic credits Claude Code with $1bn in run-rate revenue as of December 2nd.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2025/Dec/31/the-year-in-llms/",
    "published_date": "2025-12-31",
    "topics": ["LLM", "AI Agents", "Coding Agents", "Reasoning Models", "Claude Code", "Chinese AI Models", "Vibe Coding", "Prompt Injection Security", "Open Source", "Year in Review"],
    "type": "technical"
  },
  {
    "title": "AI-Generated Code Is Not Reproducible (Yet)",
    "description": "Empirical study investigating whether LLM-generated code can be successfully executed in clean environments. Researchers conducted a systematic reproducibility study of 300 complete projects generated by three leading state-of-the-art LLM-based coding agents, investigating dependency gaps in AI-generated code. Key finding: AI-generated code faces significant reproducibility challenges due to missing or incorrect dependencies, highlighting a critical gap between code generation and real-world execution.",
    "author": "Researchers (arXiv 2512.22387)",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2512.22387",
    "published_date": "2025-12-26",
    "topics": ["Code Generation", "Reproducibility", "LLM", "Dependencies", "Empirical Study", "Software Engineering"],
    "type": "technical"
  },
  {
    "title": "Developers remain willing but reluctant to use AI: The 2025 Developer Survey results are here",
    "description": "Stack Overflow's 2025 survey of 49,000+ developers reveals a critical paradox: AI tool adoption climbed to 80%, yet trust in AI accuracy fell from 40% to just 29%. Positive sentiment decreased from 72% to 60% year-over-year. Top frustration (45%): 'AI solutions that are almost right, but not quite' - 66% spend more time fixing 'almost-right' AI-generated code. When stakes are high, 75% still ask another person for help. 72% say 'vibe coding' is not part of their professional work. Only 29% trust AI accuracy vs 40% previously. AI agent adoption: 52% say agents affected their work, but primarily for personal productivity (69%). Developers learning specifically for AI: 36% in the last year. Preferred models: OpenAI (81%), Claude Sonnet more popular with professionals (45%) vs learners (30%). Key insight: future of code is about trust, not just tools.",
    "author": "Stack Overflow Team",
    "source": "Blog",
    "url": "https://stackoverflow.blog/2025/12/29/developers-remain-willing-but-reluctant-to-use-ai-the-2025-developer-survey-results-are-here/",
    "published_date": "2025-12-29",
    "topics": ["Developer Survey", "AI Adoption", "Trust in AI", "Vibe Coding", "AI Agents", "Developer Tools", "Sentiment Analysis"],
    "type": "technical"
  }
]
