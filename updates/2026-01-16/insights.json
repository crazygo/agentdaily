[
  {
    "title": "Open Responses: A Vendor-Neutral Standard for LLM APIs",
    "description": "Simon Willison discusses Open Responses, a new standardization effort for a vendor-neutral specification of the JSON API that clients can use to talk to hosted LLMs. The standard is derived from OpenAI's Responses API and has launch partners including OpenRouter, Hugging Face, LM Studio, vLLM, Ollama, and Vercel.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/15/open-responses/",
    "published_date": "2026-01-15",
    "topics": ["LLM", "API standards", "OpenAI", "vendor-neutral", "OpenRouter", "Hugging Face"],
    "type": "technical"
  },
  {
    "title": "The Design & Implementation of Fly Sprites",
    "description": "Thomas Ptacek from Fly provides insider details on Sprites, described as 'disposable computers' for quick instantiation. Sprites keep warm pools of unused machines in multiple regions and use a custom filesystem on top of S3-compatible storage with Litestream-replicated local SQLite metadata for fast checkpointing (~300ms) and restores.",
    "author": "Thomas Ptacek / Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/15/sprites/",
    "published_date": "2026-01-15",
    "topics": ["infrastructure", "sandboxes", "Fly", "SQLite", "Litestream", "JuiceFS"],
    "type": "technical"
  },
  {
    "title": "Claude Cowork Exfiltrates Files - Security Research",
    "description": "Prompt Armor discovered a security vulnerability in Claude Cowork where they constructed an attack that includes an attacker's own Anthropic API key and has the agent upload files to the api.anthropic.com/v1/files endpoint, allowing data exfiltration. This exploits Anthropic's API domain being on the allowed outbound list.",
    "author": "Simon Willison / Prompt Armor",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/14/claude-cowork-exfiltrates-files/",
    "published_date": "2026-01-14",
    "topics": ["security", "prompt injection", "Claude Cowork", "Anthropic", "exfiltration attacks", "AI agents"],
    "type": "technical"
  },
  {
    "title": "Anthropic invests $1.5 million in Python Software Foundation",
    "description": "Anthropic entered into a two-year partnership with the Python Software Foundation (PSF) to contribute $1.5 million to support the foundation's work, with emphasis on Python ecosystem security. The investment will enable security advances to CPython and PyPI, and sustain core work including the Developer in Residence program.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/13/anthropic-psf-investment/",
    "published_date": "2026-01-13",
    "topics": ["open source", "Python", "PSF", "Anthropic", "security", "funding"],
    "type": "technical"
  },
  {
    "title": "Superhuman AI Exfiltrates Emails via Prompt Injection",
    "description": "A prompt injection attack was discovered where an untrusted email manipulated Superhuman AI to submit content from dozens of sensitive emails (financial, legal, medical) to an attacker's Google Form. The root cause was a CSP rule allowing markdown images from docs.google.com - Google Forms persist data via GET requests.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/12/superhuman-exfiltration/",
    "published_date": "2026-01-12",
    "topics": ["security", "prompt injection", "Superhuman AI", "exfiltration attacks", "CSP", "AI email"],
    "type": "technical"
  },
  {
    "title": "First impressions of Claude Cowork, Anthropic's general agent",
    "description": "Comprehensive first impressions of Claude Cowork, Anthropic's new 'research preview' general agent available to Max subscribers ($100-200/month plans) as part of the updated Claude Desktop macOS application. The article includes detailed analysis of the agent's capabilities and limitations.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/12/claude-cowork/",
    "published_date": "2026-01-12",
    "topics": ["Claude Cowork", "Anthropic", "AI agents", "coding agents", "product review"],
    "type": "opinion"
  },
  {
    "title": "Don't fall into the anti-AI hype",
    "description": "Salvatore Sanfilippo argues that despite AI company valuation concerns, programming has changed forever. The post emphasizes that LLMs will help write better software faster and allow small teams to compete with bigger companies, similar to how open source software did in the 90s.",
    "author": "Salvatore Sanfilippo / Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/11/dont-fall-into-the-anti-ai-hype/",
    "published_date": "2026-01-11",
    "topics": ["AI ethics", "AI-assisted programming", "LLM", "industry trends", "open source"],
    "type": "opinion"
  },
  {
    "title": "My answers to the questions I posed about porting open source code with LLMs",
    "description": "Follow-up to Simon Willison's previous post about porting JustHTML from Python to JavaScript using Codex CLI and GPT-5.2. He answers his own ethical and legal questions about using LLMs to port open source code.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/11/answers/",
    "published_date": "2026-01-11",
    "topics": ["open source", "AI ethics", "LLM", "code porting", "AI-assisted programming"],
    "type": "opinion"
  },
  {
    "title": "Linus Torvalds on Vibe Coding with Python",
    "description": "Linus Torvalds mentions that the Python visualizer tool in his guitar-pedal-related repo was 'basically written by vibe-coding' - he cut out the middle-man (himself) and just used Google to help with the audio sample visualizer, despite knowing more about analog filters than Python.",
    "author": "Linus Torvalds / Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/11/linus-torvalds-vibe-coding/",
    "published_date": "2026-01-11",
    "topics": ["vibe coding", "Linus Torvalds", "Python", "AI-assisted programming", "LLM"],
    "type": "opinion"
  },
  {
    "title": "A Software Library with No Code - Just Conformance Tests",
    "description": "Drew Breunig's experiment: a time formatting library called 'whenwords' with no code, just a specification, AGENTS.md, and conformance tests in YAML. Pass it to a coding agent and it writes the implementation on demand. Simon Willison discusses how this meshes with his interest in conformance suites.",
    "author": "Drew Breunig / Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/10/software-library-with-no-code/",
    "published_date": "2026-01-10",
    "topics": ["testing", "AI", "coding agents", "conformance suites", "AI-assisted programming"],
    "type": "technical"
  },
  {
    "title": "Fly's new Sprites.dev: Stateful sandbox environments with checkpoint & restore",
    "description": "Fly.io launched Sprites.dev, a product addressing both developer sandboxes and API sandboxes. Simon sees it as hitting two favorite problems: a safe development environment for running coding agents AND an API for running untrusted code in a secure sandbox.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/9/sprites-dev/",
    "published_date": "2026-01-09",
    "topics": ["sandboxes", "Fly", "coding agents", "API sandboxes", "infrastructure"],
    "type": "technical"
  },
  {
    "title": "Even Linus Torvalds is trying his hand at vibe coding",
    "description": "Ars Technica reports on Linus Torvalds experimenting with AI coding tools in a GitHub project, demonstrating that even the most traditional developers are exploring AI-assisted programming approaches.",
    "author": "Ars Technica",
    "source": "TechMedia",
    "url": "https://arstechnica.com/ai/2026/01/hobby-github-repo-shows-linus-torvalds-vibe-codes-sometimes/",
    "published_date": "2026-01-12",
    "topics": ["vibe coding", "Linus Torvalds", "AI coding tools", "GitHub"],
    "type": "technical"
  },
  {
    "title": "My LLM Coding Workflow for 2026",
    "description": "Fireship released a video walking through the exact coding workflow for 2026, describing the disciplined approach to leverage AI aggressively for development tasks.",
    "author": "Fireship",
    "source": "YouTube",
    "url": "https://www.youtube.com/watch?v=24qR2030NBI",
    "published_date": "2026-01-10",
    "topics": ["AI coding workflow", "LLM", "development workflow", "coding tools"],
    "type": "tutorial"
  },
  {
    "title": "Claude is good at assembling blocks, but still falls apart",
    "description": "Hacker News discussion from 2 days ago about GPT-5 being sycophantic and comparison with Claude in pure coding contexts, with debate about effectiveness of AI coding assistants.",
    "author": "Hacker News Community",
    "source": "Community",
    "url": "https://news.ycombinator.com/item?id=46618042",
    "published_date": "2026-01-14",
    "topics": ["Claude", "GPT-5", "AI coding", "LLM", "discussion"],
    "type": "discussion"
  },
  {
    "title": "First impressions of Claude Cowork - HN Discussion",
    "description": "Hacker News discussion from 2 days ago on Claude Cowork, including debate about giving up on LLM-assisted programming and whether it's easier to express desires in code than in English.",
    "author": "Hacker News Community",
    "source": "Community",
    "url": "https://news.ycombinator.com/item?id=46612919",
    "published_date": "2026-01-14",
    "topics": ["Claude Cowork", "AI agents", "AI-assisted programming", "LLM"],
    "type": "discussion"
  },
  {
    "title": "LLMs are a 400-year-long confidence trick",
    "description": "Hacker News discussion from 3 days ago mentioning Claude Code Opus 4.5 and how it amplifies engineer intent, with philosophical debate about LLM capabilities and limitations.",
    "author": "Hacker News Community",
    "source": "Community",
    "url": "https://news.ycombinator.com/item?id=46613997",
    "published_date": "2026-01-13",
    "topics": ["Claude Code", "Opus 4.5", "LLM", "AI philosophy", "discussion"],
    "type": "discussion"
  },
  {
    "title": "Artificial Entanglement in the Fine-Tuning of Large Language Models",
    "description": "Research paper on artificial entanglement phenomenon during LLM fine-tuning, submitted to arXiv in January 2026.",
    "author": "arXiv Researchers",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2601.06788",
    "published_date": "2026-01-10",
    "topics": ["LLM", "fine-tuning", "research", "entanglement", "AI theory"],
    "type": "technical"
  },
  {
    "title": "Extracting books from production language models",
    "description": "Research paper on methods for extracting training data (books) from production language models, submitted to arXiv in January 2026.",
    "author": "A Ahmed et al.",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2601.02671",
    "published_date": "2026-01-09",
    "topics": ["LLM", "data extraction", "security", "research", "training data"],
    "type": "technical"
  },
  {
    "title": "HAL: Inducing Human-likeness in LLMs with Alignment",
    "description": "Research paper on techniques to induce more human-like behavior in LLMs through alignment methods, submitted to arXiv in January 2026.",
    "author": "M Hasan et al.",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2601.02813",
    "published_date": "2026-01-09",
    "topics": ["LLM", "alignment", "human-like behavior", "research", "AI safety"],
    "type": "technical"
  },
  {
    "title": "GDPO: Group reward-Decoupled Normalization Policy Optimization",
    "description": "Research paper on a new reinforcement learning optimization technique for multi-reward scenarios, submitted to arXiv in January 2026.",
    "author": "SY Liu et al.",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2601.05242",
    "published_date": "2026-01-09",
    "topics": ["reinforcement learning", "policy optimization", "multi-reward RL", "research"],
    "type": "technical"
  }
]
