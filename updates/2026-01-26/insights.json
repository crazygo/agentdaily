[
  {
    "title": "Science fiction writers, Comic-Con say goodbye to AI",
    "description": "TechCrunch covers how major science fiction and pop culture entities including Comic-Con are taking stances against generative AI, reflecting growing resistance in creative communities.",
    "author": "TechCrunch",
    "source": "TechMedia",
    "url": "https://techcrunch.com/2026/01/25/science-fiction-writers-comic-con-say-goodbye-to-ai/",
    "published_date": "2026-01-25",
    "topics": ["AI backlash", "creative industries", "generative AI", "policy"],
    "type": "discussion"
  },
  {
    "title": "Achieving 5x Agentic Coding Performance with Few-Shot Prompting",
    "description": "Discusses how LLMs are useful tools for programmers and how to achieve 5x performance improvements with agentic coding using few-shot prompting techniques. Published on Towards Data Science.",
    "author": "Towards Data Science",
    "source": "Platform",
    "url": "https://towardsdatascience.com/5x-agentic-coding-performance-with-few-shot-prompting/",
    "published_date": "2026-01-24",
    "topics": ["agentic coding", "few-shot prompting", "LLM performance", "productivity"],
    "type": "tutorial"
  },
  {
    "title": "OpenAI is coming for those sweet enterprise dollars in 2026",
    "description": "TechCrunch covers OpenAI's enterprise push in 2026, with Barret Zoph leading the initiative. Reports on OpenAI's strategy to capture enterprise market share with AI coding and developer tools.",
    "author": "TechCrunch",
    "source": "TechMedia",
    "url": "https://techcrunch.com/2026/01/22/openai-is-coming-for-those-sweet-enterprise-dollars-in-2026/",
    "published_date": "2026-01-22",
    "topics": ["OpenAI", "enterprise", "AI coding", "business strategy"],
    "type": "technical"
  },
  {
    "title": "Are AI agents ready for the workplace? A new benchmark raises doubts",
    "description": "TechCrunch reports on new research benchmarking how leading AI models perform on white-collar work tasks, raising questions about AI agent readiness for workplace deployment.",
    "author": "TechCrunch",
    "source": "TechMedia",
    "url": "https://techcrunch.com/2026/01/22/are-ai-agents-ready-for-the-workplace-a-new-benchmark-raises-doubts/",
    "published_date": "2026-01-22",
    "topics": ["AI agents", "benchmarks", "workplace readiness", "evaluation"],
    "type": "technical"
  },
  {
    "title": "Optimizing AI-Assisted Code Generation",
    "description": "Recent arXiv paper examining how AI-assisted code-generation tools have transformed software development, with analysis of optimization strategies and effectiveness.",
    "author": "arXiv",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2412.10953",
    "published_date": "2026-01-21",
    "topics": ["AI code generation", "software development", "optimization", "research"],
    "type": "technical"
  },
  {
    "title": "Best Coding LLMs January 2026 Rankings",
    "description": "Comprehensive rankings comparing GPT-5.2, Claude Opus 4.5, Gemini 3, DeepSeek, and other leading AI models for coding and software development tasks.",
    "author": "WhatLLM.org",
    "source": "Blog",
    "url": "https://whatllm.org/blog/best-coding-models-january-2026",
    "published_date": "2026-01-20",
    "topics": ["LLM", "coding benchmarks", "model comparison", "AI coding"],
    "type": "technical"
  },
  {
    "title": "Electricity use of AI coding agents",
    "description": "Simon Willison analyzes the energy and water costs of AI coding agents like Claude Code, estimating heavy usage at 4,400 typical queries daily ($15-20 cost), equivalent to running a dishwasher. Challenges 'median query' metrics as misleading for coding agents.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/20/electricity-use-of-ai-coding-agents/",
    "published_date": "2026-01-20",
    "topics": ["AI energy usage", "LLM costs", "environmental impact", "coding agents"],
    "type": "technical"
  },
  {
    "title": "Using Local LLMs to Discover High-Performance Algorithms",
    "description": "Explores using local LLMs to discover high-performance algorithms, including benchmarking code within the generation loop itself. Published on Towards Data Science.",
    "author": "Towards Data Science",
    "source": "Platform",
    "url": "https://towardsdatascience.com/using-local-llms-to-discover-high-performance-algorithms/",
    "published_date": "2026-01-20",
    "topics": ["local LLM", "algorithms", "benchmarking", "code generation"],
    "type": "technical"
  },
  {
    "title": "Why Inference in Large Models Becomes Decomposable After Training",
    "description": "arXiv paper by J. Jin et al. analyzing decomposability in large model inference and why this property emerges after training.",
    "author": "J. Jin et al.",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2601.15871",
    "published_date": "2026-01-20",
    "topics": ["LLM inference", "decomposability", "model training", "research"],
    "type": "technical"
  },
  {
    "title": "Top 5 AI Tools for Visual Studio 2026",
    "description": "Visual Studio Magazine's coverage of the top 5 AI tools integrated with Visual Studio for enhanced development productivity in 2026.",
    "author": "Visual Studio Magazine",
    "source": "TechMedia",
    "url": "https://visualstudiomagazine.com/articles/2026/01/20/top-5-ai-tools-for-visual-studio-2026.aspx",
    "published_date": "2026-01-20",
    "topics": ["Visual Studio", "AI tools", "IDE", "Microsoft"],
    "type": "opinion"
  },
  {
    "title": "Device-Native Autonomous Agents for Privacy-Preserving Negotiations",
    "description": "arXiv paper introducing privacy-preserving AI agent systems for autonomous negotiations, addressing device-native agent architectures for privacy.",
    "author": "J. Roy et al.",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2601.00911",
    "published_date": "2026-01-19",
    "topics": ["autonomous agents", "privacy", "negotiation", "device-native AI"],
    "type": "technical"
  },
  {
    "title": "Challenges and Research Directions for Large Language Model Inference Hardware",
    "description": "arXiv paper by X. Ma et al. examining hardware challenges for LLM inference and research directions for optimization.",
    "author": "X. Ma et al.",
    "source": "Paper",
    "url": "https://arxiv.org/abs/2601.05047",
    "published_date": "2026-01-19",
    "topics": ["LLM inference", "hardware", "optimization", "research"],
    "type": "technical"
  }
]