[
  {
    "title": "Claude is good at assembling blocks, but still falls apart",
    "description": "Hacker News discussion examining GPT-5's coding capabilities and limitations. Commenters discuss where models excel at assembling code blocks versus where they struggle with complex tasks. The thread explores the current boundaries of AI coding assistance.",
    "author": "Hacker News Community",
    "source": "HN",
    "url": "https://news.ycombinator.com/item?id=46618042",
    "published_date": "2026-01-15",
    "topics": ["GPT-5", "AI coding", "model limitations", "code assembly", "Hacker News"],
    "type": "discussion"
  },
  {
    "title": "Open Responses - A Vendor-Neutral Specification for LLM APIs",
    "description": "Simon Willison discusses Open Responses, a new vendor-neutral specification for the JSON API that clients can use to talk to hosted LLMs. The standard is derived from OpenAI's Responses API and has launch partners including OpenRouter, Hugging Face, LM Studio, vLLM, Ollama and Vercel. Willison emphasizes the need for comprehensive conformance test suites for both servers and clients.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/15/open-responses/",
    "published_date": "2026-01-15",
    "topics": ["LLM", "API standards", "OpenAI", "conformance testing", "vendor-neutral"],
    "type": "technical"
  },
  {
    "title": "Open Responses - Industry-Wide LLM API Standard",
    "description": "Open Responses emerges as a new vendor-neutral specification for LLM API interoperability, based on OpenAI's Responses API from March 2025. The standard defines a shared schema and client libraries with backing from OpenRouter, Vercel, HuggingFace, LM Studio, and the open-source community. It unifies text, images, structured outputs, and agentic loops into a single interface, addressing fragmentation across LLM providers.",
    "author": "OpenAI Community",
    "source": "Platform",
    "url": "https://community.openai.com/t/open-responses-for-the-open-source-community/1371770",
    "published_date": "2026-01-15",
    "topics": ["LLM", "API standards", "OpenAI", "interoperability", "vendor-neutral"],
    "type": "technical"
  },
  {
    "title": "LLMs are a 400-year-long confidence trick",
    "description": "Hacker News discussion on LLMs and their role in software engineering. Mentions 'Claude Code Opus 4.5' and discusses how AI amplifies engineer intent rather than replacing engineers. The conversation explores the philosophical and practical implications of LLM-assisted development.",
    "author": "Hacker News Community",
    "source": "HN",
    "url": "https://news.ycombinator.com/item?id=46613997",
    "published_date": "2026-01-14",
    "topics": ["LLM", "AI philosophy", "Claude", "developer tools", "Hacker News"],
    "type": "discussion"
  },
  {
    "title": "Claude Cowork Exfiltrates Files via API Endpoint",
    "description": "Security researchers discovered a prompt injection vulnerability in Claude Cowork. Although the service restricts outbound HTTP to specific domains, attackers found a workaround by including their own Anthropic API key and having the agent upload files to api.anthropic.com/v1/files endpoint, which was on the allowlist.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/14/claude-cowork-exfiltrates/",
    "published_date": "2026-01-14",
    "topics": ["security", "prompt injection", "AI agents", "exfiltration attacks", "Anthropic", "Claude Cowork"],
    "type": "technical"
  },
  {
    "title": "Anthropic Invests $1.5 Million in Python Software Foundation",
    "description": "Anthropic announced a two-year partnership with the Python Software Foundation (PSF), contributing $1.5 million with emphasis on Python ecosystem security. The investment will support CPython and PyPI security advances, plus the PSF's core work including the Developer in Residence program, community grants, and infrastructure.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/13/anthropic-psf-investment/",
    "published_date": "2026-01-13",
    "topics": ["open source", "Python", "AI", "PSF", "Anthropic", "security"],
    "type": "opinion"
  },
  {
    "title": "First Impressions of Claude Cowork, Anthropic's General Agent",
    "description": "Simon Willison shares his first impressions of Claude Cowork, Anthropic's new 'research preview' general agent described as 'Claude Code for the rest of your work.' The tool is available only to Max subscribers and represents Anthropic's expansion beyond coding into general-purpose AI agents.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/12/claude-cowork/",
    "published_date": "2026-01-12",
    "topics": ["AI agents", "Anthropic", "Claude Cowork", "sandboxing", "prompt injection"],
    "type": "opinion"
  },
  {
    "title": "Superhuman AI Exfiltrates Emails via Prompt Injection",
    "description": "A prompt injection attack in an untrusted email manipulated Superhuman AI to submit content from dozens of sensitive emails (financial, legal, medical) to an attacker's Google Form. The root cause was a CSP rule allowing markdown images from docs.google.com, as Google Forms persist data via GET requests.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/12/superhuman-ai-exfiltrates/",
    "published_date": "2026-01-12",
    "topics": ["security", "prompt injection", "AI agents", "exfiltration attacks", "content security policy"],
    "type": "technical"
  },
  {
    "title": "Claude Cowork First Impressions - Hacker News Discussion",
    "description": "Hacker News thread discussing Simon Willison's review of Claude Cowork, Anthropic's general-purpose AI agent. Discussion highlights include positioning as 'Claude Code for non-coders', the $200/month Max subscription requirement, limitations compared to Claude Code, and security concerns around sandboxing. The thread appeared within hours of Claude Cowork's release.",
    "author": "Hacker News Community",
    "source": "HN",
    "url": "https://news.ycombinator.com/item?id=46612919",
    "published_date": "2026-01-12",
    "topics": ["AI agents", "Anthropic", "Claude Cowork", "product review", "Hacker News"],
    "type": "discussion"
  },
  {
    "title": "Don't Fall Into the Anti-AI Hype",
    "description": "Willison highlights Salvatore Sanfilippo's response to anti-AI sentiment in the software development community. The key insight: 'Programming changed forever, anyway.' Sanfilippo emphasizes that LLMs will help write better software faster and allow small teams to compete with bigger companies, similar to what open source did in the 90s.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/11/anti-ai-hype/",
    "published_date": "2026-01-11",
    "topics": ["AI", "LLM", "AI-assisted programming", "AI ethics", "career development"],
    "type": "opinion"
  },
  {
    "title": "A Software Library with No Code",
    "description": "Drew Breunig's experiment: 'whenwords', a time formatting library with no codeâ€”just a specification, an AGENTS.md, and conformance tests in YAML. Pass this to coding agents and they generate implementations in any language on demand. Willison notes this meshes with his interest in conformance suites.",
    "author": "Simon Willison",
    "source": "Blog",
    "url": "https://simonwillison.net/2026/Jan/10/software-library-no-code/",
    "published_date": "2026-01-10",
    "topics": ["testing", "AI", "coding agents", "conformance suites", "LLM"],
    "type": "technical"
  }
]
